{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f18a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "kcl_files = glob.glob(\"../CornBeltersData/*.csv\")\n",
    "cornbelters_files = glob.glob(\"../CornBeltersData/*.csv\")\n",
    "all_files =  kcl_files + cornbelters_files\n",
    "\n",
    "# Read and concatenate all CSVs into one DataFrame\n",
    "data_list = [pd.read_csv(f) for f in all_files]\n",
    "df = pd.concat(data_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9dcaed",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pitch_by_pitch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\maxim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pitch_by_pitch'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 112\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Apply Stuff+ prediction row-wise\u001b[39;00m\n\u001b[0;32m    111\u001b[0m mapping_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_delta_run_exp_by_outcome_count.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpitch_by_pitch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(combined_columns)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Map the data: Group by pitch_by_pitch, Balls, and Strikes, and calculate the mean of delta_run_exp_mean\u001b[39;00m\n\u001b[0;32m    114\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmerge(mapping_data, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpitch_by_pitch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBalls\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrikes\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maxim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\maxim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3817\u001b[0m     ):\n\u001b[0;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pitch_by_pitch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Define offspeed pitches\n",
    "offspeed_pitches = ['Sinker', 'Curveball', 'Slider', 'Cutter']\n",
    "def combined_columns(event):\n",
    "    #If there is a value in KorBB return that since PlayResult sometimes does not have KorBB\n",
    "    if not pd.isna(event['KorBB']):\n",
    "        return event['KorBB']\n",
    "    #If the ball is in play in pitchcall we want to return the result to map it\n",
    "    if event['PitchCall'] == 'InPlay':\n",
    "        return event['PlayResult']\n",
    "    #Since we already have if there's a strikeout or if there's an inplay\n",
    "    else:\n",
    "        return event['PitchCall']\n",
    "# Difference calculation functions\n",
    "def calculate_ff_diff(event):\n",
    "    \"\"\"Calculate fastball speed difference with error handling\"\"\"\n",
    "    if pd.notna(event['RelSpeed']) and pd.notna(event['TaggedPitchType']) and event['TaggedPitchType'] in offspeed_pitches:\n",
    "        fastball_avg = df[(df['Pitcher'] == event['Pitcher']) & \n",
    "                         (df['TaggedPitchType'] == 'Fastball')]['RelSpeed'].mean()\n",
    "        if pd.notna(fastball_avg):\n",
    "            return fastball_avg - event['RelSpeed']\n",
    "    return np.nan\n",
    "\n",
    "def calculate_ivb_diff(event):\n",
    "    \"\"\"Calculate induced vertical break difference with error handling\"\"\"\n",
    "    if pd.notna(event['InducedVertBreak']) and pd.notna(event['TaggedPitchType']) and event['TaggedPitchType'] in offspeed_pitches:\n",
    "        fastball_avg = df[(df['Pitcher'] == event['Pitcher']) & \n",
    "                         (df['TaggedPitchType'] == 'Fastball')]['InducedVertBreak'].mean()\n",
    "        if pd.notna(fastball_avg):\n",
    "            return fastball_avg - event['InducedVertBreak']\n",
    "    return np.nan\n",
    "\n",
    "def calculate_hb_diff(event):\n",
    "    \"\"\"Calculate horizontal break difference with error handling\"\"\"\n",
    "    if pd.notna(event['HorzBreak']) and pd.notna(event['TaggedPitchType']) and event['TaggedPitchType'] in offspeed_pitches:\n",
    "        fastball_avg = df[(df['Pitcher'] == event['Pitcher']) & \n",
    "                         (df['TaggedPitchType'] == 'Fastball')]['HorzBreak'].mean()\n",
    "        if pd.notna(fastball_avg):\n",
    "            return fastball_avg - event['HorzBreak']\n",
    "    return np.nan\n",
    "\n",
    "# Apply difference calculations\n",
    "df['ff_diff'] = df.apply(calculate_ff_diff, axis=1)\n",
    "df['ivb_diff'] = df.apply(calculate_ivb_diff, axis=1)\n",
    "df['hb_diff'] = df.apply(calculate_hb_diff, axis=1)\n",
    "\n",
    "# One-hot encode pitch types\n",
    "# One-hot encode pitch types\n",
    "dummies = pd.get_dummies(df['TaggedPitchType'], prefix='PitchType', dtype=float)\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "# Define trained dummy columns\n",
    "trained_dummy_columns = [\n",
    "    'PitchType_Changeup',\n",
    "    'PitchType_Curveball',\n",
    "    'PitchType_Cutter',\n",
    "    'PitchType_Fastball',\n",
    "    'PitchType_Knuckleball',\n",
    "    'PitchType_Sinker',\n",
    "    'PitchType_Slider',\n",
    "    'PitchType_Splitter'\n",
    "]\n",
    "\n",
    "# Add missing dummy columns with 0s\n",
    "for col in trained_dummy_columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = 0.0\n",
    "\n",
    "# Drop extra dummy columns\n",
    "df = df.drop(columns=[col for col in df.columns if col.startswith('PitchType_') and col not in trained_dummy_columns])\n",
    "\n",
    "# Define model features\n",
    "features = ['RelSpeed', 'SpinRate', 'RelHeight', 'RelSide', 'Extension',\n",
    "            'InducedVertBreak', 'HorzBreak', 'VertApprAngle', 'ZoneSpeed',\n",
    "            'ff_diff', 'ivb_diff', 'hb_diff'] + trained_dummy_columns\n",
    "\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "y = df['delta_run_exp_mean']\n",
    "# Load models\n",
    "with open(\"../Stuff+/stuff_plus_model.pkl\", \"rb\") as f:\n",
    "    stuff_plus_model = pickle.load(f)\n",
    "\n",
    "\n",
    "def predict_stuff_plus(event):\n",
    "    if all(item in event for item in features):\n",
    "        # Given values\n",
    "        df['']\n",
    "        std = 0.17713484357387707\n",
    "        scale_factor = 100  # Controls spread; one std moves score by 10\n",
    "\n",
    "        # Convert event[features] to a 2D array for prediction\n",
    "        input_data = event[features].values.reshape(1, -1)\n",
    "\n",
    "        # Predict stuff_plus\n",
    "        stuff_plus = stuff_plus_model.predict(input_data)[0]\n",
    "\n",
    "        # Scale to make 100 the average\n",
    "        stuff_plus_scaled = 100 + ((stuff_plus - mean) / std * scale_factor)\n",
    "\n",
    "        return stuff_plus_scaled # Return scalar value\n",
    "    else:\n",
    "        return np.nan\n",
    "# Apply Stuff+ prediction row-wise\n",
    "\n",
    "\n",
    "mapping_data = pd.read_csv('mean_delta_run_exp_by_outcome_count.csv')\n",
    "df['pitch_by_pitch'] = df.apply(combined_columns,axis=1)# Map the data: Group by pitch_by_pitch, Balls, and Strikes, and calculate the mean of delta_run_exp_mean\n",
    "df = df.merge(mapping_data, on=['pitch_by_pitch', 'Balls', 'Strikes'], how='left')\n",
    "df['Stuff+'] = df.apply(predict_stuff_plus, axis=1)\n",
    "df = df[['PitchUUID','Stuff+','delta_run_exp_mean']]\n",
    "\n",
    "# Add Good Swing Decision\n",
    "# Save the modified dataframe\n",
    "df.to_csv('../BaseballSavant/Stuff+UUID.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9117ae10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
