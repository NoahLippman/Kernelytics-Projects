{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3ee5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee80158",
   "metadata": {},
   "outputs": [],
   "source": [
    "cornbelters_files = glob.glob(\"../KCLData/*.csv\")\n",
    "other_files = glob.glob(\"../CornBeltersData/*.csv\")\n",
    "\n",
    "all_files = cornbelters_files + other_files\n",
    "\n",
    "# Read and concatenate all CSVs into one DataFrame\n",
    "stuff_plus = [pd.read_csv(f) for f in all_files]\n",
    "df = pd.concat(stuff_plus, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88a9c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = df[df['BatterSide'] == 'Left']\n",
    "df_right = df[df['BatterSide'] == 'Right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54816a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine PitchCall KorBB and PlayResult into one column\n",
    "def combined_columns(event):\n",
    "    #If there is a value in KorBB return that since PlayResult sometimes does not have KorBB\n",
    "    if not pd.isna(event['KorBB']):\n",
    "        return event['KorBB']\n",
    "    #If the ball is in play in pitchcall we want to return the result to map it\n",
    "    if event['PitchCall'] == 'InPlay':\n",
    "        return event['PlayResult']\n",
    "    #Since we already have if there's a strikeout or if there's an inplay\n",
    "    else:\n",
    "        return event['PitchCall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "226f15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(df):\n",
    "    \"\"\"Validate DataFrame columns and data types.\"\"\"\n",
    "    required_columns = ['GameID', 'Inning', 'PAofInning', 'Outs', 'OutsOnPlay', 'RunsScored', 'pitch_by_pitch', 'Balls', 'Strikes']\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    for col in required_columns:\n",
    "        if df[col].isna().any():\n",
    "            print(f\"Warning: {col} contains {df[col].isna().sum()} missing values\")\n",
    "    \n",
    "    # Validate data types and ranges\n",
    "    if not df['PAofInning'].apply(lambda x: pd.isna(x) or (isinstance(x, (int, float)) and x >= 1)).all():\n",
    "        raise ValueError(\"PAofInning must be numeric and >= 1 or NaN\")\n",
    "    if not df['Outs'].isin([0, 1, 2, np.nan]).all():\n",
    "        print(f\"Warning: Invalid values in Outs. Expected 0, 1, 2, or NaN. Found: {df['Outs'].unique()}\")\n",
    "    if not df['OutsOnPlay'].apply(lambda x: pd.isna(x) or (isinstance(x, (int, float)) and x >= 0)).all():\n",
    "        raise ValueError(\"OutsOnPlay must be numeric and >= 0 or NaN\")\n",
    "    if not df['RunsScored'].apply(lambda x: pd.isna(x) or (isinstance(x, (int, float)) and x >= 0)).all():\n",
    "        raise ValueError(\"RunsScored must be numeric and >= 0 or NaN\")\n",
    "    if not df['Balls'].isin([0, 1, 2, 3, 4, np.nan]).all():\n",
    "        print(f\"Warning: Invalid values in Balls. Expected 0-4 or NaN. Found: {df['Balls'].unique()}\")\n",
    "    if not df['Strikes'].isin([0, 1, 2, np.nan]).all():\n",
    "        print(f\"Warning: Invalid values in Strikes. Expected 0-2 or NaN. Found: {df['Strikes'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe8c940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_base_state(df_inning):\n",
    "    \"\"\"Infer base state (None or Runners) based on prior plays in the inning.\"\"\"\n",
    "    if df_inning.empty:\n",
    "        return pd.Series(['None'] * len(df_inning), index=df_inning.index)\n",
    "    \n",
    "    base_state = []\n",
    "    runners_on = False\n",
    "    df_inning = df_inning.sort_values('PAofInning')  # Ensure sorted order\n",
    "    \n",
    "    for i, (idx, row) in enumerate(df_inning.iterrows()):\n",
    "        # Reset runners at the start of an inning or after 3 outs\n",
    "        if row['PAofInning'] == 1 or (i > 0 and df_inning.iloc[i-1]['Outs'] == 2):\n",
    "            runners_on = False\n",
    "        # Outcomes that likely add runners (non-outs)\n",
    "        if row['pitch_by_pitch'] in ['Single', 'Double', 'Triple', 'Walk', 'HitByPitch', 'Error', 'FieldersChoice', 'IntentionalWalk']:\n",
    "            runners_on = True\n",
    "        # Outcomes that clear bases or end inning\n",
    "        elif row['pitch_by_pitch'] in ['HomeRun', 'Strikeout', 'Out', 'Sacrifice']:\n",
    "            runners_on = False\n",
    "        base_state.append('Runners' if runners_on else 'None')\n",
    "    \n",
    "    return pd.Series(base_state, index=df_inning.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29abf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_run_expectancy_matrix(df):\n",
    "    \"\"\"\n",
    "    Create a run expectancy matrix for college baseball data.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with 'GameID', 'Inning', 'PAofInning', 'Outs', 'OutsOnPlay', 'RunsScored', 'pitch_by_pitch'.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Run expectancy matrix with mean runs per base-out state.\n",
    "    pd.DataFrame: Updated DataFrame with base_state and base_out_state columns.\n",
    "    \"\"\"\n",
    "    # Validate input data\n",
    "    validate_data(df)\n",
    "    \n",
    "    # Create a copy and clean data\n",
    "    df = df.copy()\n",
    "    df['GameID'] = df['GameID'].astype(str)\n",
    "    df['Inning'] = df['Inning'].astype(str)\n",
    "    df = df.dropna(subset=['GameID', 'Inning', 'PAofInning'])\n",
    "    df['Outs'] = df['Outs'].fillna(0).astype(int)\n",
    "    df['OutsOnPlay'] = df['OutsOnPlay'].fillna(0).astype(int)\n",
    "    df['RunsScored'] = df['RunsScored'].fillna(0).astype(float)\n",
    "    df['Balls'] = df['Balls'].fillna(0).astype(int)\n",
    "    df['Strikes'] = df['Strikes'].fillna(0).astype(int)\n",
    "    non_scoring = ['Foul', 'BallCalled', 'StrikeCalled', 'StrikeSwinging', 'FoulTip']\n",
    "    df.loc[df['pitch_by_pitch'].isin(non_scoring), 'RunsScored'] = 0\n",
    "    df.loc[df['pitch_by_pitch'] == 'StrikeoutSwinging', 'pitch_by_pitch'] = 'Strikeout'\n",
    "    \n",
    "    # Create inning identifier\n",
    "    df['inning_id'] = df['GameID'] + '_' + df['Inning']\n",
    "    \n",
    "    # Reindex PAofInning to ensure sequential values\n",
    "    df['PAofInning'] = df.groupby('inning_id').cumcount() + 1\n",
    "    \n",
    "    # Sort by inning and PAofInning\n",
    "    df = df.sort_values(['inning_id', 'PAofInning'])\n",
    "    \n",
    "    # Infer base state for each pitch\n",
    "    try:\n",
    "        df['base_state'] = df.groupby('inning_id', group_keys=False).apply(infer_base_state)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in infer_base_state: {e}\")\n",
    "        for inning_id, group in df.groupby('inning_id'):\n",
    "            if not group['PAofInning'].is_monotonic_increasing or group['PAofInning'].min() < 1:\n",
    "                print(f\"Problematic inning_id: {inning_id}\")\n",
    "                print(group[['PAofInning', 'Outs', 'OutsOnPlay', 'pitch_by_pitch', 'RunsScored']])\n",
    "        raise\n",
    "    \n",
    "    # Create base-out state\n",
    "    df['base_out_state'] = df['base_state'] + '_' + df['Outs'].astype(str)\n",
    "    \n",
    "    # Calculate cumulative runs to end of inning\n",
    "    runs_per_play = df.groupby(['inning_id', 'PAofInning', 'base_out_state'])['RunsScored'].sum().reset_index()\n",
    "    runs_per_play['runs_to_end'] = runs_per_play.groupby('inning_id')['RunsScored'].transform(lambda x: x[::-1].cumsum()[::-1])\n",
    "    \n",
    "    # Compute mean run expectancy for each base-out state\n",
    "    re_matrix = runs_per_play.groupby('base_out_state')['runs_to_end'].mean().reset_index()\n",
    "    re_matrix.rename(columns={'runs_to_end': 'run_expectancy'}, inplace=True)\n",
    "    \n",
    "    return re_matrix, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c61cf1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta_run_exp(df, re_matrix):\n",
    "    \"\"\"\n",
    "    Calculate delta run expectancy for each pitch event using OutsOnPlay.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with pitch data and base_out_state.\n",
    "    re_matrix (pd.DataFrame): Run expectancy matrix.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with added 'delta_run_exp' column.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['start_base_out_state'] = df['base_out_state']\n",
    "    \n",
    "    # Infer end state after pitch\n",
    "    df['end_outs'] = df['Outs'] + df['OutsOnPlay']\n",
    "    df['end_outs'] = df['end_outs'].clip(upper=3)\n",
    "    df['end_base_state'] = df['base_state']\n",
    "    \n",
    "    # Update base state for outcomes that clear or add runners\n",
    "    df.loc[df['pitch_by_pitch'].isin(['HomeRun', 'Strikeout', 'Out', 'Sacrifice']), 'end_base_state'] = 'None'\n",
    "    df.loc[df['pitch_by_pitch'].isin(['Single', 'Double', 'Triple', 'Walk', 'HitByPitch', 'Error', 'IntentionalWalk']), 'end_base_state'] = 'Runners'\n",
    "    \n",
    "    # Create end base-out state\n",
    "    df['end_base_out_state'] = df['end_base_state'] + '_' + df['end_outs'].astype(str)\n",
    "    \n",
    "    # Merge start and end run expectancy\n",
    "    df = df.merge(re_matrix, left_on='start_base_out_state', right_on='base_out_state', how='left')\n",
    "    df.rename(columns={'run_expectancy': 'start_re'}, inplace=True)\n",
    "    df = df.merge(re_matrix, left_on='end_base_out_state', right_on='base_out_state', how='left')\n",
    "    df.rename(columns={'run_expectancy': 'end_re'}, inplace=True)\n",
    "    \n",
    "    # Handle missing run expectancy values\n",
    "    df['start_re'] = df['start_re'].fillna(0)\n",
    "    df['end_re'] = df['end_re'].fillna(0)\n",
    "    \n",
    "    # Calculate delta run expectancy\n",
    "    df['delta_run_exp'] = df['end_re'] - df['start_re'] + df['RunsScored']\n",
    "    \n",
    "    # Drop temporary columns\n",
    "    df.drop(['start_re', 'end_re', 'base_out_state_x', 'base_out_state_y', 'end_outs', 'end_base_state', 'end_base_out_state'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5e0f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_delta_run_exp(df):\n",
    "    \"\"\"\n",
    "    Calculate mean delta run expectancy by pitch outcome and count.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with 'pitch_by_pitch', 'delta_run_exp', 'Balls', 'Strikes'.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with mean delta_run_exp for each outcome and count.\n",
    "    \"\"\"\n",
    "    mean_delta_run_exp = df.groupby(['TaggedPitchType', 'Balls', 'Strikes'])['delta_run_exp'].mean().reset_index()\n",
    "    mean_delta_run_exp.rename(columns={'delta_run_exp': 'delta_run_exp_mean'}, inplace=True)\n",
    "    return mean_delta_run_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6ae0ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_delta_run_exp_df(df):\n",
    "    \"\"\"\n",
    "    Build DataFrame with delta run expectancy for each pitch.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with 'GameID', 'Inning', 'PAofInning', 'Outs', 'OutsOnPlay', 'RunsScored', \n",
    "                       'pitch_by_pitch', 'Balls', 'Strikes'.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with 'delta_run_exp' and 'delta_run_exp_mean' columns.\n",
    "    pd.DataFrame: Run expectancy matrix.\n",
    "    pd.DataFrame: Mean delta run expectancy by outcome and count.\n",
    "    \"\"\"\n",
    "    # Create run expectancy matrix and update DataFrame with base states\n",
    "    re_matrix, df_with_base_states = create_run_expectancy_matrix(df)\n",
    "    \n",
    "    # Calculate delta run expectancy for each pitch\n",
    "    df_with_delta = calculate_delta_run_exp(df_with_base_states, re_matrix)\n",
    "    \n",
    "    # Calculate mean delta run expectancy by outcome and count\n",
    "    mean_delta_run_exp_df = calculate_mean_delta_run_exp(df_with_delta)\n",
    "    \n",
    "    # Merge mean delta run expectancy back into DataFrame\n",
    "    df_final = df_with_delta.merge(mean_delta_run_exp_df, on=['TaggedPitchType', 'Balls', 'Strikes'], how='left')\n",
    "    \n",
    "    # Handle missing mean delta run expectancy values\n",
    "    df_final['delta_run_exp_mean'] = df_final['delta_run_exp_mean'].fillna(0)\n",
    "    \n",
    "    return df_final, re_matrix, mean_delta_run_exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e3053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left['pitch_by_pitch'] = df_left.apply(combined_columns,axis=1)\n",
    "df_right['pitch_by_pitch'] = df_right.apply(combined_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b60dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = df_left.dropna(subset=['Outs','pitch_by_pitch','PAofInning','GameID','TaggedPitchType'])\n",
    "df_right = df_right.dropna(subset=['Outs','pitch_by_pitch','PAofInning','GameID','TaggedPitchType'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "260bffbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isu_mvquirk\\AppData\\Local\\Temp\\ipykernel_26172\\242118967.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_left['OutsOnPlay'] = df_left['OutsOnPlay'].fillna(0)\n",
      "C:\\Users\\isu_mvquirk\\AppData\\Local\\Temp\\ipykernel_26172\\242118967.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_left['RunsScored'] = df_left['RunsScored'].fillna(0)\n",
      "C:\\Users\\isu_mvquirk\\AppData\\Local\\Temp\\ipykernel_26172\\242118967.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_right['OutsOnPlay'] = df_right['OutsOnPlay'].fillna(0)\n",
      "C:\\Users\\isu_mvquirk\\AppData\\Local\\Temp\\ipykernel_26172\\242118967.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_right['RunsScored'] = df_right['RunsScored'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "df_left['OutsOnPlay'] = df_left['OutsOnPlay'].fillna(0)\n",
    "df_left['RunsScored'] = df_left['RunsScored'].fillna(0)\n",
    "df_right['OutsOnPlay'] = df_right['OutsOnPlay'].fillna(0)\n",
    "df_right['RunsScored'] = df_right['RunsScored'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c449b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40db4995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isu_mvquirk\\AppData\\Local\\Temp\\ipykernel_26172\\3406481458.py:40: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['base_state'] = df.groupby('inning_id', group_keys=False).apply(infer_base_state)\n"
     ]
    }
   ],
   "source": [
    "df_final, re_matrix, mean_delta_run_exp_df = build_delta_run_exp_df(df_left)\n",
    "df_final.to_csv('left_college_pitch_pitch_data_with_delta_run_exp.csv', index=False)\n",
    "re_matrix.to_csv('left_college_run_pitch_expectancy_matrix.csv', index=False)\n",
    "mean_delta_run_exp_df.to_csv('left_mean_pitch_delta_run_exp_by_outcome_count.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64c36f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isu_mvquirk\\AppData\\Local\\Temp\\ipykernel_26172\\3406481458.py:40: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['base_state'] = df.groupby('inning_id', group_keys=False).apply(infer_base_state)\n"
     ]
    }
   ],
   "source": [
    "df_final, re_matrix, mean_delta_run_exp_df = build_delta_run_exp_df(df_right)\n",
    "df_final.to_csv('right_college_pitch_pitch_data_with_delta_run_exp.csv', index=False)\n",
    "re_matrix.to_csv('right_college_run_pitch_expectancy_matrix.csv', index=False)\n",
    "mean_delta_run_exp_df.to_csv('right_mean_pitch_delta_run_exp_by_outcome_count.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784cc89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['PlateLocHeight','PlateLocSide','pitch_by_pitch','strikes','balls','outs']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
